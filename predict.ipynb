{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import densenet\n",
    "from tensorflow.keras.applications.densenet import preprocess_input\n",
    "from tensorflow.keras.layers import Dense, LSTM, Input, Embedding, Conv2D, Concatenate, Flatten, Add, Dropout, GRU\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import re\n",
    "import pickle\n",
    "from PIL import Image\n",
    "from skimage.transform import resize\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(img_name):\n",
    "    image = Image.open(img_name)\n",
    "    X = np.asarray(image.convert(\"RGB\"))\n",
    "    X = np.asarray(X)\n",
    "    X = preprocess_input(X)\n",
    "    X = resize(X, (224,224,3))\n",
    "    X = np.expand_dims(X, axis=0)\n",
    "    X = np.asarray(X)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chex = densenet.DenseNet121(include_top=False, weights = None, input_shape=(224,224,3), pooling=\"avg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = chex.output\n",
    "X = Dense(14, activation=\"sigmoid\", name=\"predictions\")(X)\n",
    "model = Model(inputs=chex.input, outputs=X)\n",
    "model.load_weights(r'./utils/Image_features_enc.h5')\n",
    "imgModel = Model(inputs = model.input, outputs = model.layers[-2].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading\n",
    "with open('tokenizer.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "keras_preprocessing.text.Tokenizer"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer.index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.word_counts) + 1\n",
    "f = open('Image_features_attention.pickle','rb') # contains the features from chexNet\n",
    "Xnet_Features = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"embedding_matrix.pickle\", \"rb\") as output_file:\n",
    "    embedding_matrix = pickle.load(output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Text_Input (InputLayer)         [(None, 153)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Embedding_layer (Embedding)     (None, 153, 300)     393900      Text_Input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "LSTM1 (LSTM)                    (None, 153, 256)     570368      Embedding_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Image_1 (InputLayer)            [(None, 2048)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "LSTM2 (LSTM)                    (None, 256)          525312      LSTM1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_encoder (Dense)           (None, 256)          524544      Image_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout1 (Dropout)              (None, 256)          0           LSTM2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 256)          0           dense_encoder[0][0]              \n",
      "                                                                 dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "fc1 (Dense)                     (None, 256)          65792       add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dropout2 (Dropout)              (None, 256)          0           fc1[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "Output_layer (Dense)            (None, 1313)         337441      dropout2[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 2,417,357\n",
      "Trainable params: 2,023,457\n",
      "Non-trainable params: 393,900\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input1 = Input(shape=(2048), name='Image_1')\n",
    "dense1 = Dense(256, kernel_initializer=tf.keras.initializers.glorot_uniform(seed = 56), name='dense_encoder')(input1)\n",
    "\n",
    "input2 = Input(shape=(153), name='Text_Input')\n",
    "emb_layer = Embedding(input_dim = vocab_size, output_dim = 300, input_length=153, mask_zero=True, trainable=False, \n",
    "                weights=[embedding_matrix], name=\"Embedding_layer\")\n",
    "emb = emb_layer(input2)\n",
    "\n",
    "LSTM1 = LSTM(units=256, activation='tanh', recurrent_activation='sigmoid', use_bias=True, \n",
    "            kernel_initializer=tf.keras.initializers.glorot_uniform(seed=23),\n",
    "            recurrent_initializer=tf.keras.initializers.orthogonal(seed=7),\n",
    "            bias_initializer=tf.keras.initializers.zeros(), return_sequences=True, name=\"LSTM1\")(emb)\n",
    "#LSTM1_output = LSTM1(emb)\n",
    "\n",
    "LSTM2 = LSTM(units=256, activation='tanh', recurrent_activation='sigmoid', use_bias=True, \n",
    "            kernel_initializer=tf.keras.initializers.glorot_uniform(seed=23),\n",
    "            recurrent_initializer=tf.keras.initializers.orthogonal(seed=7),\n",
    "            bias_initializer=tf.keras.initializers.zeros(), name=\"LSTM2\")\n",
    "LSTM2_output = LSTM2(LSTM1)\n",
    "\n",
    "dropout1 = Dropout(0.5, name='dropout1')(LSTM2_output)\n",
    "\n",
    "dec =  tf.keras.layers.Add()([dense1, dropout1])\n",
    "\n",
    "fc1 = Dense(256, activation='relu', kernel_initializer=tf.keras.initializers.he_normal(seed = 63), name='fc1')\n",
    "fc1_output = fc1(dec)\n",
    "dropout2 = Dropout(0.4, name='dropout2')(fc1_output)\n",
    "output_layer = Dense(vocab_size, activation='softmax', name='Output_layer')\n",
    "output = output_layer(dropout2)\n",
    "\n",
    "encoder_decoder = Model(inputs = [input1, input2], outputs = output)\n",
    "encoder_decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_decoder.load_weights(r\"./Weights_re/encoder_decoder_epoch_20.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder\n",
    "encoder_input = encoder_decoder.input[0]\n",
    "encoder_output = encoder_decoder.get_layer('dense_encoder').output\n",
    "encoder_model = Model(encoder_input, encoder_output)\n",
    "\n",
    "\n",
    "# decoder\n",
    "text_input = encoder_decoder.input[1]\n",
    "enc_output = Input(shape=(256,), name='Enc_Output')\n",
    "text_output = encoder_decoder.get_layer('LSTM2').output\n",
    "add1 = tf.keras.layers.Add()([text_output, enc_output])\n",
    "fc_1 = fc1(add1)\n",
    "decoder_output = output_layer(fc_1)\n",
    "decoder_model = Model(inputs = [text_input, enc_output], outputs = decoder_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beamsearch(image, beam_width):\n",
    "    \n",
    "    start = [tokenizer.word_index['startseq']]\n",
    "\n",
    "    sequences = [[start, 0]]\n",
    "    \n",
    "    img_features = image\n",
    "    img_features = encoder_model.predict(img_features)\n",
    "    finished_seq = []\n",
    "    \n",
    "    for i in range(153):\n",
    "        all_candidates = []\n",
    "        new_seq = []\n",
    "        for s in sequences:\n",
    "\n",
    "            text_input = pad_sequences([s[0]], 153, padding='post')\n",
    "            predictions = decoder_model.predict([text_input,img_features])\n",
    "            top_words = np.argsort(predictions[0])[-beam_width:]\n",
    "            seq, score = s\n",
    "            \n",
    "            for t in top_words:\n",
    "                candidates = [seq + [t], score - np.log(predictions[0][t])]\n",
    "                all_candidates.append(candidates)\n",
    "                \n",
    "        sequences = sorted(all_candidates, key = lambda l: l[1])[:beam_width]\n",
    "        # checks for 'endseq' in each seq in the beam\n",
    "        count = 0\n",
    "        for seq,score in sequences:\n",
    "            if seq[len(seq)-1] == tokenizer.word_index['endseq']:\n",
    "                score = score/len(seq)   # normalized\n",
    "                finished_seq.append([seq, score])\n",
    "                count+=1\n",
    "            else:\n",
    "                new_seq.append([seq, score])\n",
    "        beam_width -= count\n",
    "        sequences = new_seq\n",
    "        \n",
    "        # if all the sequences reaches its end before 155 timesteps\n",
    "        if not sequences:\n",
    "            break\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "    sequences = finished_seq[-1] \n",
    "    rep = sequences[0]\n",
    "    score = sequences[1]\n",
    "    temp = []\n",
    "    rep.pop(0)\n",
    "    for word in rep:\n",
    "        if word != tokenizer.word_index['endseq']:\n",
    "            temp.append(tokenizer.index_word[word])\n",
    "        else:\n",
    "            break    \n",
    "    rep = ' '.join(e for e in temp)        \n",
    "    \n",
    "    return rep, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedysearch(img):\n",
    "    image = img # Extract the initial chexnet features for the images\n",
    "    input_ = 'startseq'  # initial partial report\n",
    "    image_features = encoder_model.predict(image) # encoder output\n",
    "    \n",
    "    result = [] \n",
    "    for i in range(153):\n",
    "        input_tok = [tokenizer.word_index[w] for w in input_.split()]\n",
    "        input_padded = pad_sequences([input_tok], 153, padding='post')\n",
    "        predictions = decoder_model.predict([input_padded, image_features])\n",
    "        arg = np.argmax(predictions)\n",
    "        if arg != tokenizer.word_index['endseq']:   # endseq\n",
    "            result.append(tokenizer.index_word[arg])\n",
    "            input_ = input_ + ' ' + tokenizer.index_word[arg]\n",
    "        else:\n",
    "            break\n",
    "    rep = ' '.join(e for e in result)\n",
    "    return rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(img1, img2):\n",
    "    img1 = load_image(img1)\n",
    "    img1_features = imgModel.predict(img1)\n",
    "    img2 = load_image(img2)\n",
    "    img2_features = imgModel.predict(img2)\n",
    "    image_input = np.concatenate((img1_features, img2_features), axis=1)\n",
    "    # print(image_input.shape)\n",
    "    y_pred = beamsearch(image_input, 5)\n",
    "    print(y_pred)\n",
    "    y_pred = greedysearch(image_input)\n",
    "    print(y_pred)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('the cardiomediastinal silhouette within normal limits for size and contour the lungs are normally inflated without evidence focal airspace disease pleural effusion pneumothorax osseous structures are within normal limits for patient age', 0.2372301875594156)\n",
      "the heart normal size the mediastinum unremarkable the lungs are clear\n"
     ]
    }
   ],
   "source": [
    "predict(r\"C:\\Users\\prana\\OneDrive\\Desktop\\ProjectsInProgress\\MDP_Xray\\imgs\\CXR152_IM-0335-1001.png\", r\"C:\\Users\\prana\\OneDrive\\Desktop\\ProjectsInProgress\\MDP_Xray\\imgs\\CXR152_IM-0335-2001.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('the cardiomediastinal silhouette within normal limits for size and contour the lungs are normally inflated without evidence focal airspace disease pleural effusion pneumothorax no acute bone abnormality', 0.23247014566895186)\n",
      "the heart normal size the mediastinum unremarkable the lungs are clear\n"
     ]
    }
   ],
   "source": [
    "predict(r\"C:\\Users\\prana\\OneDrive\\Desktop\\ProjectsInProgress\\MDP_Xray\\imgs\\CXR1_1_IM-0001-4001.png\", r\"C:\\Users\\prana\\OneDrive\\Desktop\\ProjectsInProgress\\MDP_Xray\\imgs\\CXR1_1_IM-0001-3001.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('the cardiomediastinal silhouette within normal limits for size and contour the lungs are normally inflated without evidence focal airspace disease pleural effusion pneumothorax no acute bone abnormality', 0.22209578860214418)\n",
      "the lungs are clear there no pleural effusion the heart and mediastinum are normal the skeletal structures and soft tissues are normal\n"
     ]
    }
   ],
   "source": [
    "predict(r\"C:\\Users\\prana\\OneDrive\\Desktop\\ProjectsInProgress\\MDP_Xray\\imgs\\CXR8_IM-2333-1001.png\", r\"C:\\Users\\prana\\OneDrive\\Desktop\\ProjectsInProgress\\MDP_Xray\\imgs\\CXR8_IM-2333-2001.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('dl')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dfb7b30c51b8e1d3a47b3d4579b0301ae9e907709d427aafeb8a0fa711ef1ada"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
