{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "b20a74d9a1864efaaf13c1cde49ffccc",
    "deepnote_cell_height": 52.390625,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "https://towardsdatascience.com/image-captioning-using-deep-learning-fe0d929cf337\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "cell_id": "5bd495d67f1c4578a328712c9d30fc11",
    "deepnote_cell_height": 719,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 17006,
    "execution_start": 1656164306153,
    "source_hash": "8bfb4ed7",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting graphviz\n",
      "  Downloading graphviz-0.20-py3-none-any.whl (46 kB)\n",
      "Installing collected packages: graphviz\n",
      "Successfully installed graphviz-0.20\n"
     ]
    }
   ],
   "source": [
    "!pip install graphviz "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": "6f197fc5-1f91-4d03-953e-82aeb39050ce",
    "deepnote_cell_height": 369,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1484,
    "execution_start": 1656164323209,
    "source_hash": "2d9dd40f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import pickle\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, LSTM, Input, Embedding, Conv2D, Concatenate, Flatten, Add, Dropout, GRU\n",
    "import random\n",
    "import datetime\n",
    "from nltk.translate.bleu_score import sentence_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_set():\n",
    "    obj = reqd[np.random.randint(len(reqd))]\n",
    "    for i in range(len(obj[\"imgs\"])):\n",
    "        plt.subplot(1, len(obj[\"imgs\"]),i+1)\n",
    "        plt.axis('off')\n",
    "        img = plt.imread(get_img_path(obj[\"imgs\"][i]))\n",
    "        plt.imshow(img)\n",
    "    print(obj[\"desc\"])\n",
    "\n",
    "def get_random_set2(df, k):\n",
    "    obj = df[k]\n",
    "    for i in range(len(obj[\"imgs\"])):\n",
    "        plt.subplot(1, len(obj[\"imgs\"]),i+1)\n",
    "        plt.axis('off')\n",
    "        img = plt.imread(get_img_path(obj[\"imgs\"][i]))\n",
    "        plt.imshow(img)\n",
    "    print(obj[\"desc\"])\n",
    "    \n",
    "def get_img_path(x):\n",
    "    return \"./imgs/\"+x+\".png\"\n",
    "\n",
    "from PIL import Image\n",
    "def load_image(img_name):\n",
    "    '''Function to load the image'''\n",
    "    image = Image.open(img_name)\n",
    "    image = image.resize((224,224))\n",
    "    image_array = np.asarray(image.convert(\"RGB\"))\n",
    "    image_array = image_array / 255.\n",
    "    \n",
    "    X = np.expand_dims(image_array, axis=0)\n",
    "    X = np.asarray(X) \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": "f447d9a6e20245a79b0fd5f58eb86948",
    "deepnote_cell_height": 117,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 64,
    "execution_start": 1656164324697,
    "source_hash": "55c93b86",
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = pd.read_csv('df_train.csv')\n",
    "test_dataset = pd.read_csv('df_test.csv')\n",
    "cv_dataset = pd.read_csv('df_cv.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": "ef2f15def2214c6e93a96a18ee7badc3",
    "deepnote_cell_height": 613.4375,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 91,
    "execution_start": 1656164334170,
    "source_hash": "b8ae154d",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>desc</th>\n",
       "      <th>img1</th>\n",
       "      <th>img2</th>\n",
       "      <th>img3</th>\n",
       "      <th>img4</th>\n",
       "      <th>img5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>startseq right upper lobe airspace disease con...</td>\n",
       "      <td>CXR3069_IM-1432-1001</td>\n",
       "      <td>CXR3069_IM-1432-2001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>startseq mediastinal contours are normal lungs...</td>\n",
       "      <td>CXR2629_IM-1116-1001</td>\n",
       "      <td>CXR2629_IM-1116-2001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>startseq cardiomediastinal contours are unchan...</td>\n",
       "      <td>CXR1888_IM-0576-1001</td>\n",
       "      <td>CXR1888_IM-0576-4004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>startseq heart size normal the lungs are clear...</td>\n",
       "      <td>CXR2248_IM-0844-1001</td>\n",
       "      <td>CXR2248_IM-0844-1002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>startseq the cardiomediastinal contours are wi...</td>\n",
       "      <td>CXR3408_IM-1648-1001</td>\n",
       "      <td>CXR3408_IM-1648-1002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2063</th>\n",
       "      <td>2331</td>\n",
       "      <td>startseq the heart normal size the mediastinum...</td>\n",
       "      <td>CXR2243_IM-0840-1001</td>\n",
       "      <td>CXR2243_IM-0840-2001</td>\n",
       "      <td>CXR2243_IM-0840-3001</td>\n",
       "      <td>CXR2243_IM-0840-4001</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2064</th>\n",
       "      <td>2332</td>\n",
       "      <td>startseq normal heart size normal mediastinal ...</td>\n",
       "      <td>CXR1356_IM-0231-1001</td>\n",
       "      <td>CXR1356_IM-0231-2001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2065</th>\n",
       "      <td>2333</td>\n",
       "      <td>startseq frontal and lateral views the chest s...</td>\n",
       "      <td>CXR1883_IM-0572-1001</td>\n",
       "      <td>CXR1883_IM-0572-2001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2066</th>\n",
       "      <td>2334</td>\n",
       "      <td>startseq normal heart size and mediastinal con...</td>\n",
       "      <td>CXR2622_IM-1110-1001</td>\n",
       "      <td>CXR2622_IM-1110-1002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2067</th>\n",
       "      <td>2335</td>\n",
       "      <td>startseq there are low lung volumes with bibas...</td>\n",
       "      <td>CXR2185_IM-0795-1001</td>\n",
       "      <td>CXR2185_IM-0795-2001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2068 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                               desc  \\\n",
       "0              0  startseq right upper lobe airspace disease con...   \n",
       "1              1  startseq mediastinal contours are normal lungs...   \n",
       "2              2  startseq cardiomediastinal contours are unchan...   \n",
       "3              3  startseq heart size normal the lungs are clear...   \n",
       "4              4  startseq the cardiomediastinal contours are wi...   \n",
       "...          ...                                                ...   \n",
       "2063        2331  startseq the heart normal size the mediastinum...   \n",
       "2064        2332  startseq normal heart size normal mediastinal ...   \n",
       "2065        2333  startseq frontal and lateral views the chest s...   \n",
       "2066        2334  startseq normal heart size and mediastinal con...   \n",
       "2067        2335  startseq there are low lung volumes with bibas...   \n",
       "\n",
       "                      img1                  img2                  img3  \\\n",
       "0     CXR3069_IM-1432-1001  CXR3069_IM-1432-2001                   NaN   \n",
       "1     CXR2629_IM-1116-1001  CXR2629_IM-1116-2001                   NaN   \n",
       "2     CXR1888_IM-0576-1001  CXR1888_IM-0576-4004                   NaN   \n",
       "3     CXR2248_IM-0844-1001  CXR2248_IM-0844-1002                   NaN   \n",
       "4     CXR3408_IM-1648-1001  CXR3408_IM-1648-1002                   NaN   \n",
       "...                    ...                   ...                   ...   \n",
       "2063  CXR2243_IM-0840-1001  CXR2243_IM-0840-2001  CXR2243_IM-0840-3001   \n",
       "2064  CXR1356_IM-0231-1001  CXR1356_IM-0231-2001                   NaN   \n",
       "2065  CXR1883_IM-0572-1001  CXR1883_IM-0572-2001                   NaN   \n",
       "2066  CXR2622_IM-1110-1001  CXR2622_IM-1110-1002                   NaN   \n",
       "2067  CXR2185_IM-0795-1001  CXR2185_IM-0795-2001                   NaN   \n",
       "\n",
       "                      img4 img5  \n",
       "0                      NaN  NaN  \n",
       "1                      NaN  NaN  \n",
       "2                      NaN  NaN  \n",
       "3                      NaN  NaN  \n",
       "4                      NaN  NaN  \n",
       "...                    ...  ...  \n",
       "2063  CXR2243_IM-0840-4001  NaN  \n",
       "2064                   NaN  NaN  \n",
       "2065                   NaN  NaN  \n",
       "2066                   NaN  NaN  \n",
       "2067                   NaN  NaN  \n",
       "\n",
       "[2068 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": "9b7e3bbb1e8a4c6c9cbfe509d813777b",
    "deepnote_cell_height": 261,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_start": 1656164435922,
    "source_hash": "4877bcfd",
    "tags": []
   },
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": "2a3ff8f401b141a9b0dff7d27c6b7ca9",
    "deepnote_cell_height": 66,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 22,
    "execution_start": 1656164449826,
    "source_hash": "6903f708",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_id": "9f8e3a3e082a4de5a7d21bbbebd833ee",
    "deepnote_cell_type": "code",
    "owner_user_id": "2c307b87-7ef7-4cda-b00b-122cc2b79247",
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(filters='!\"#$%&()*+,-/:;<=>?@[\\\\]^_`{|}~\\t\\n')\n",
    "tokenizer.fit_on_texts(train_dataset.desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1313"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(tokenizer.word_counts) + 1\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('Image_features_attention.pickle','rb') # contains the features from chexNet\n",
    "Xnet_Features = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    with open(r\"embedding_matrix.pickle\", \"rb\") as output_file:\n",
    "        embedding_matrix = pickle.load(output_file)\n",
    "    print(\"loaded\")\n",
    "except:\n",
    "    embedding_matrix = np.zeros((vocab_size,300))\n",
    "    filepath = r\"./utils/glove.6B/glove.6B.300d.txt\"\n",
    "    with open(filepath, encoding=\"utf8\") as f:\n",
    "        for line in f:\n",
    "            word, *vector = line.split()\n",
    "            if word in tokenizer.word_index.keys():\n",
    "                idx = tokenizer.word_index[word]\n",
    "                embedding_matrix[idx] = np.array(\n",
    "                    vector, dtype=np.float32)[:300]\n",
    "    with open(r\"embedding_matrix.pickle\", \"wb\") as output_file:\n",
    "        pickle.dump(embedding_matrix, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(id_, report):\n",
    "    '''Loads the Image Features with their corresponding Ids'''\n",
    "#     test_2827 train_2335\n",
    "    if id_ > 2827:\n",
    "        img_feature = Xnet_Features[\"cv_\"+str(id_)][0]\n",
    "    elif id_ > 2335:\n",
    "        img_feature = Xnet_Features[\"test_\"+str(id_)][0]\n",
    "    else:\n",
    "        img_feature = Xnet_Features[\"train_\"+str(id_)][0]\n",
    "    return img_feature, report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(img_name, caption):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((img_name, caption))\n",
    "    # Use map to load the numpy files in parallel\n",
    "    dataset = dataset.map(lambda item1, item2: tf.numpy_function(load_image, [item1, item2], [tf.float32, tf.string]),\n",
    "                          num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    # Shuffle and batch\n",
    "    dataset = dataset.shuffle(500).batch(BATCH_SIZE).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset shapes: (<unknown>, <unknown>), types: (tf.float32, tf.string)>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator = create_dataset(train_dataset.iloc[:,0], train_dataset.desc)\n",
    "train_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_generator = create_dataset(cv_dataset.iloc[:,0], cv_dataset.desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Text_Input (InputLayer)         [(None, 153)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Embedding_layer (Embedding)     (None, 153, 300)     393900      Text_Input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "LSTM1 (LSTM)                    (None, 153, 256)     570368      Embedding_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "Image_1 (InputLayer)            [(None, 2048)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "LSTM2 (LSTM)                    (None, 256)          525312      LSTM1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_encoder (Dense)           (None, 256)          524544      Image_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout1 (Dropout)              (None, 256)          0           LSTM2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 256)          0           dense_encoder[0][0]              \n",
      "                                                                 dropout1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "fc1 (Dense)                     (None, 256)          65792       add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout2 (Dropout)              (None, 256)          0           fc1[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "Output_layer (Dense)            (None, 1313)         337441      dropout2[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 2,417,357\n",
      "Trainable params: 2,023,457\n",
      "Non-trainable params: 393,900\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input1 = Input(shape=(2048), name='Image_1')\n",
    "dense1 = Dense(256, kernel_initializer=tf.keras.initializers.glorot_uniform(seed = 56), name='dense_encoder')(input1)\n",
    "\n",
    "input2 = Input(shape=(153), name='Text_Input')\n",
    "emb_layer = Embedding(input_dim = vocab_size, output_dim = 300, input_length=153, mask_zero=True, trainable=False, \n",
    "                weights=[embedding_matrix], name=\"Embedding_layer\")\n",
    "emb = emb_layer(input2)\n",
    "\n",
    "LSTM1 = LSTM(units=256, activation='tanh', recurrent_activation='sigmoid', use_bias=True, \n",
    "            kernel_initializer=tf.keras.initializers.glorot_uniform(seed=23),\n",
    "            recurrent_initializer=tf.keras.initializers.orthogonal(seed=7),\n",
    "            bias_initializer=tf.keras.initializers.zeros(), return_sequences=True, name=\"LSTM1\")(emb)\n",
    "#LSTM1_output = LSTM1(emb)\n",
    "\n",
    "LSTM2 = LSTM(units=256, activation='tanh', recurrent_activation='sigmoid', use_bias=True, \n",
    "            kernel_initializer=tf.keras.initializers.glorot_uniform(seed=23),\n",
    "            recurrent_initializer=tf.keras.initializers.orthogonal(seed=7),\n",
    "            bias_initializer=tf.keras.initializers.zeros(), name=\"LSTM2\")\n",
    "LSTM2_output = LSTM2(LSTM1)\n",
    "\n",
    "dropout1 = Dropout(0.5, name='dropout1')(LSTM2_output)\n",
    "\n",
    "dec =  tf.keras.layers.Add()([dense1, dropout1])\n",
    "\n",
    "fc1 = Dense(256, activation='relu', kernel_initializer=tf.keras.initializers.he_normal(seed = 63), name='fc1')\n",
    "fc1_output = fc1(dec)\n",
    "dropout2 = Dropout(0.4, name='dropout2')(fc1_output)\n",
    "output_layer = Dense(vocab_size, activation='softmax', name='Output_layer')\n",
    "output = output_layer(dropout2)\n",
    "\n",
    "encoder_decoder = Model(inputs = [input1, input2], outputs = output)\n",
    "encoder_decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(encoder_decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = tf.keras.losses.CategoricalCrossentropy(from_logits=False, reduction='auto')\n",
    "\n",
    "def maskedLoss(y_true, y_pred):\n",
    "    #getting mask value\n",
    "    mask = tf.math.logical_not(tf.math.equal(y_true, 0))\n",
    "    \n",
    "    #calculating the loss\n",
    "    loss_ = loss_function(y_true, y_pred)\n",
    "    \n",
    "    #converting mask dtype to loss_ dtype\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    \n",
    "    #applying the mask to loss\n",
    "    loss_ = loss_*mask\n",
    "    \n",
    "    #getting mean over all the values\n",
    "    loss_ = tf.reduce_mean(loss_)\n",
    "    return loss_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1313, 300)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_decoder.compile(optimizer, loss = maskedLoss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bytes_to_string(arr):\n",
    "    '''The generator gives provides data in bytes. This function converts them back to strings for manipulation'''\n",
    "    for i in range(len(arr)):\n",
    "        arr[i] = arr[i].decode('utf-8')\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(images, reports):\n",
    "    '''This function takes the batch of data and converts them into a new dataset(A WORD BY WORD DATASET)'''\n",
    "    imgs = []\n",
    "    in_reports = []\n",
    "    out_reports = []\n",
    "    for i in range(len(images)):\n",
    "        sequence = [tokenizer.word_index[e] for e in reports[i].split() if e in tokenizer.word_index.keys()]\n",
    "      #  print(sequence)\n",
    "        for j in range(1,len(sequence)):\n",
    "            in_seq = sequence[:j]\n",
    "            out_seq = sequence[j]\n",
    "            out_seq = tf.keras.utils.to_categorical(out_seq, num_classes=vocab_size)\n",
    "            imgs.append(images[i])\n",
    "          #  print(in_seq)\n",
    "            in_reports.append(in_seq)\n",
    "           # print(out_seq)\n",
    "            out_reports.append(out_seq)\n",
    "    return np.array(imgs), np.array(in_reports), np.array(out_reports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "train_log_dir = 'Tensorboard/logs_m1/fit3/' + current_time + '/train'\n",
    "val_log_dir = 'Tensorboard/logs_m1/fit3/' + current_time + '/test'\n",
    "train_summary_writer = tf.summary.create_file_writer(train_log_dir)\n",
    "val_summary_writer = tf.summary.create_file_writer(val_log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH :  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prana\\AppData\\Local\\Temp\\ipykernel_28904\\85539252.py:18: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return np.array(imgs), np.array(in_reports), np.array(out_reports)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.0033988541603519194,  Val Loss: 0.0030873050132105427\n",
      "Time Taken for this Epoch : 392.8474745750427 sec\n",
      "EPOCH :  2\n",
      "Training Loss: 0.0029646353669413902,  Val Loss: 0.002589465021305988\n",
      "Time Taken for this Epoch : 413.4568979740143 sec\n",
      "EPOCH :  3\n",
      "Training Loss: 0.0025642738902472515,  Val Loss: 0.0022834883176631503\n",
      "Time Taken for this Epoch : 339.41609168052673 sec\n",
      "EPOCH :  4\n",
      "Training Loss: 0.0022942615596919643,  Val Loss: 0.0020640030570869003\n",
      "Time Taken for this Epoch : 331.6139030456543 sec\n",
      "EPOCH :  5\n",
      "Training Loss: 0.0021123053081536372,  Val Loss: 0.0019294517415185128\n",
      "Time Taken for this Epoch : 330.2767524719238 sec\n",
      "EPOCH :  6\n",
      "Training Loss: 0.0019868127241426583,  Val Loss: 0.0018830453045666218\n",
      "Time Taken for this Epoch : 331.7625858783722 sec\n",
      "EPOCH :  7\n",
      "Training Loss: 0.0018867052644871327,  Val Loss: 0.001786282627783235\n",
      "Time Taken for this Epoch : 3036.2138550281525 sec\n",
      "EPOCH :  8\n",
      "Training Loss: 0.0018009650980306117,  Val Loss: 0.001722438294710892\n",
      "Time Taken for this Epoch : 371.7466313838959 sec\n",
      "EPOCH :  9\n",
      "Training Loss: 0.001737690304222257,  Val Loss: 0.0016976260212099841\n",
      "Time Taken for this Epoch : 370.58902502059937 sec\n",
      "EPOCH :  10\n",
      "Training Loss: 0.0016717746731869521,  Val Loss: 0.0016710628424921343\n",
      "Time Taken for this Epoch : 366.4085202217102 sec\n",
      "EPOCH :  11\n",
      "Training Loss: 0.001615370690290417,  Val Loss: 0.0016644190088094723\n",
      "Time Taken for this Epoch : 363.4606628417969 sec\n",
      "EPOCH :  12\n",
      "Training Loss: 0.0015563023099232289,  Val Loss: 0.0016316483247905008\n",
      "Time Taken for this Epoch : 363.093537569046 sec\n",
      "EPOCH :  13\n",
      "Training Loss: 0.0015047389632217637,  Val Loss: 0.0016218441793875349\n",
      "Time Taken for this Epoch : 374.0683591365814 sec\n",
      "EPOCH :  14\n",
      "Training Loss: 0.0014733031905275217,  Val Loss: 0.0016174708725884557\n",
      "Time Taken for this Epoch : 362.5257828235626 sec\n",
      "EPOCH :  15\n",
      "Training Loss: 0.001434975575345258,  Val Loss: 0.0016005526957733015\n",
      "Time Taken for this Epoch : 366.46981048583984 sec\n",
      "EPOCH :  16\n",
      "Training Loss: 0.0013858286278214634,  Val Loss: 0.0016110525842035009\n",
      "Time Taken for this Epoch : 326.5051920413971 sec\n",
      "EPOCH :  17\n",
      "Training Loss: 0.0013526596855942387,  Val Loss: 0.0015865691051247619\n",
      "Time Taken for this Epoch : 350.7413384914398 sec\n",
      "EPOCH :  18\n",
      "Training Loss: 0.0013087372680441762,  Val Loss: 0.001578614799185626\n",
      "Time Taken for this Epoch : 327.44932103157043 sec\n",
      "EPOCH :  19\n",
      "Training Loss: 0.0012670216894214402,  Val Loss: 0.0016193630102451049\n",
      "Time Taken for this Epoch : 380.7109417915344 sec\n",
      "EPOCH :  20\n",
      "Training Loss: 0.0012453834290242418,  Val Loss: 0.0016132665595280067\n",
      "Time Taken for this Epoch : 386.2278072834015 sec\n"
     ]
    }
   ],
   "source": [
    "epoch_train_loss = []\n",
    "epoch_val_loss = []\n",
    "\n",
    "for epoch in range(20):\n",
    "    print('EPOCH : ',epoch+1)\n",
    "    start = time.time()\n",
    "    batch_loss_tr = 0\n",
    "    batch_loss_vl = 0\n",
    "    \n",
    "    for img, report in train_generator:\n",
    "        r1 = bytes_to_string(report.numpy())\n",
    "        img_input, rep_input, output_word = convert(img.numpy(), r1)\n",
    "        rep_input = pad_sequences(rep_input, maxlen=153, padding='post')\n",
    "        results = encoder_decoder.train_on_batch([img_input, rep_input], output_word)\n",
    "\n",
    "        batch_loss_tr += results\n",
    "    \n",
    "    train_loss = batch_loss_tr/(len(train_dataset)//14)\n",
    " #   print('Saving Tensorboard')\n",
    "    with train_summary_writer.as_default():\n",
    "        tf.summary.scalar('loss', train_loss, step = epoch)\n",
    "    \n",
    "    for img, report in cv_generator:\n",
    "        \n",
    "        r1 = bytes_to_string(report.numpy())\n",
    "        img_input, rep_input, output_word = convert(img.numpy(), r1)\n",
    "        rep_input = pad_sequences(rep_input, maxlen=153, padding='post')\n",
    "        results = encoder_decoder.test_on_batch([img_input, rep_input], output_word)\n",
    "        batch_loss_vl += results\n",
    "    \n",
    "    val_loss = batch_loss_vl/(len(cv_dataset)//14)\n",
    "    \n",
    "    with val_summary_writer.as_default():\n",
    "        tf.summary.scalar('loss', val_loss, step = epoch)\n",
    "\n",
    "    epoch_train_loss.append(train_loss)\n",
    "\n",
    "    epoch_val_loss.append(val_loss)\n",
    "    \n",
    "    print('Training Loss: {},  Val Loss: {}'.format(train_loss, val_loss))\n",
    "    print('Time Taken for this Epoch : {} sec'.format(time.time()-start))   \n",
    "    encoder_decoder.save_weights('Weights_re/encoder_decoder_epoch_'+ str(epoch+1) + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>desc</th>\n",
       "      <th>img1</th>\n",
       "      <th>img2</th>\n",
       "      <th>img3</th>\n",
       "      <th>img4</th>\n",
       "      <th>img5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>startseq right upper lobe airspace disease con...</td>\n",
       "      <td>CXR3069_IM-1432-1001</td>\n",
       "      <td>CXR3069_IM-1432-2001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>startseq mediastinal contours are normal lungs...</td>\n",
       "      <td>CXR2629_IM-1116-1001</td>\n",
       "      <td>CXR2629_IM-1116-2001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>startseq cardiomediastinal contours are unchan...</td>\n",
       "      <td>CXR1888_IM-0576-1001</td>\n",
       "      <td>CXR1888_IM-0576-4004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>startseq heart size normal the lungs are clear...</td>\n",
       "      <td>CXR2248_IM-0844-1001</td>\n",
       "      <td>CXR2248_IM-0844-1002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>startseq the cardiomediastinal contours are wi...</td>\n",
       "      <td>CXR3408_IM-1648-1001</td>\n",
       "      <td>CXR3408_IM-1648-1002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2063</th>\n",
       "      <td>2331</td>\n",
       "      <td>startseq the heart normal size the mediastinum...</td>\n",
       "      <td>CXR2243_IM-0840-1001</td>\n",
       "      <td>CXR2243_IM-0840-2001</td>\n",
       "      <td>CXR2243_IM-0840-3001</td>\n",
       "      <td>CXR2243_IM-0840-4001</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2064</th>\n",
       "      <td>2332</td>\n",
       "      <td>startseq normal heart size normal mediastinal ...</td>\n",
       "      <td>CXR1356_IM-0231-1001</td>\n",
       "      <td>CXR1356_IM-0231-2001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2065</th>\n",
       "      <td>2333</td>\n",
       "      <td>startseq frontal and lateral views the chest s...</td>\n",
       "      <td>CXR1883_IM-0572-1001</td>\n",
       "      <td>CXR1883_IM-0572-2001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2066</th>\n",
       "      <td>2334</td>\n",
       "      <td>startseq normal heart size and mediastinal con...</td>\n",
       "      <td>CXR2622_IM-1110-1001</td>\n",
       "      <td>CXR2622_IM-1110-1002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2067</th>\n",
       "      <td>2335</td>\n",
       "      <td>startseq there are low lung volumes with bibas...</td>\n",
       "      <td>CXR2185_IM-0795-1001</td>\n",
       "      <td>CXR2185_IM-0795-2001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2068 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                               desc  \\\n",
       "0              0  startseq right upper lobe airspace disease con...   \n",
       "1              1  startseq mediastinal contours are normal lungs...   \n",
       "2              2  startseq cardiomediastinal contours are unchan...   \n",
       "3              3  startseq heart size normal the lungs are clear...   \n",
       "4              4  startseq the cardiomediastinal contours are wi...   \n",
       "...          ...                                                ...   \n",
       "2063        2331  startseq the heart normal size the mediastinum...   \n",
       "2064        2332  startseq normal heart size normal mediastinal ...   \n",
       "2065        2333  startseq frontal and lateral views the chest s...   \n",
       "2066        2334  startseq normal heart size and mediastinal con...   \n",
       "2067        2335  startseq there are low lung volumes with bibas...   \n",
       "\n",
       "                      img1                  img2                  img3  \\\n",
       "0     CXR3069_IM-1432-1001  CXR3069_IM-1432-2001                   NaN   \n",
       "1     CXR2629_IM-1116-1001  CXR2629_IM-1116-2001                   NaN   \n",
       "2     CXR1888_IM-0576-1001  CXR1888_IM-0576-4004                   NaN   \n",
       "3     CXR2248_IM-0844-1001  CXR2248_IM-0844-1002                   NaN   \n",
       "4     CXR3408_IM-1648-1001  CXR3408_IM-1648-1002                   NaN   \n",
       "...                    ...                   ...                   ...   \n",
       "2063  CXR2243_IM-0840-1001  CXR2243_IM-0840-2001  CXR2243_IM-0840-3001   \n",
       "2064  CXR1356_IM-0231-1001  CXR1356_IM-0231-2001                   NaN   \n",
       "2065  CXR1883_IM-0572-1001  CXR1883_IM-0572-2001                   NaN   \n",
       "2066  CXR2622_IM-1110-1001  CXR2622_IM-1110-1002                   NaN   \n",
       "2067  CXR2185_IM-0795-1001  CXR2185_IM-0795-2001                   NaN   \n",
       "\n",
       "                      img4 img5  \n",
       "0                      NaN  NaN  \n",
       "1                      NaN  NaN  \n",
       "2                      NaN  NaN  \n",
       "3                      NaN  NaN  \n",
       "4                      NaN  NaN  \n",
       "...                    ...  ...  \n",
       "2063  CXR2243_IM-0840-4001  NaN  \n",
       "2064                   NaN  NaN  \n",
       "2065                   NaN  NaN  \n",
       "2066                   NaN  NaN  \n",
       "2067                   NaN  NaN  \n",
       "\n",
       "[2068 rows x 7 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "1fa986b9-0fc0-429d-a98a-d2a7e7ed4ab5",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
